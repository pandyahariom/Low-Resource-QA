# Does learning from language family help? A case study on a low-resource question answering task


We are currently in process of uploading our models to Hugging Face...... and code to this repo.
Some of our already uploaded models can be accessed using following links:

## Fine-Tuned Model at Hugging Face  ðŸ¤—


| Model     |      mBERT      |  XLM-RoBERTa | IndicBERT |
|:----------:|:-------------:|:-------------:|:-------------:|
|  Joint MLM training on Hindi (hi) and Bengali (be) follwed by QA larning on SQuAD-TyDi-MLQA (in sequence)| [indic-hi-be-MLM-SQuAD-TyDi-MLQA](https://huggingface.co/hapandya/indic-hi-be-MLM-SQuAD-TyDi-MLQA) | [mBERT-hi-be-MLM-SQuAD-TyDi-MLQA](https://huggingface.co/hapandya/mBERT-hi-be-MLM-SQuAD-TyDi-MLQA) | [xlmr-large-hi-be-MLM-SQuAD-TyDi-MLQA	](https://huggingface.co/hapandya/xlmr-large-hi-be-MLM-SQuAD-TyDi-MLQA) |
|  Joint MLM training on Hindi (hi) and Telugu (te) follwed by QA larning on SQuAD-TyDi-MLQA (in sequence)| [indic-hi-te-MLM-SQuAD-TyDi-MLQA](https://huggingface.co/hapandya/indic-hi-te-MLM-SQuAD-TyDi-MLQA) | [mBERT-hi-te-MLM-SQuAD-TyDi-MLQA](https://huggingface.co/hapandya/mBERT-hi-te-MLM-SQuAD-TyDi-MLQA) | [xlmr-large-hi-te-MLM-SQuAD-TyDi-MLQA	](https://huggingface.co/hapandya/xlmr-large-hi-te-MLM-SQuAD-TyDi-MLQA) |
